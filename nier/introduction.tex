\section{Introduction}
\label{sec:intro}

%\begin{figure}[t]
%  \begin{center}
%    \includegraphics[width=0.95\columnwidth]{figs/workflow.eps}
%    \caption{Workflow}
%    \label{fig:Normal workflow for most multi-tier service oriented systems}
%  \end{center}
%\end{figure}

\begin{figure}[ht]
  \begin{center}
    \includegraphics[width=0.5\textwidth]{figs/motivation.eps}
    \caption{Workflow of a two-tier system with \parikshan, which allows the user to do online debugging in a parallel debug-container cloned from the back-end server, which receives the same input.}
    \label{fig:motivation}
  \end{center}
\end{figure}

As application software grows and gets more complicated, debugging large scale applications has become increasingly important. 
%This problem is compounded by the recent trend in software engineering industry by large companies towards DevOps\cite{devops}. 
The recent trend towards DevOps\cite{devops} by the software engineering industry further compounds this problem by requiring a fast and rapid resolution towards any software bug.
DevOps stresses on close coupling between software developers and operators, and to merge the operations of both. 
Most companies which have adopted DevOps have very frequent releases and hence focus on a very short time to a bug fix, patch and release in order to realize continuous delivery (Facebook mobile has 2 releases a day, and Flickr has 10 deployment cycles per day).
However, it is extremely difficult to meet the quick debugging demands of the DevOps environment, as it is difficult to recreate buggy executions in an offline development environment.

\textbf{The past:} Traditional debugging approaches use tools such as gdb, valgrind \cite{valgrind}, which allows developers to trace the execution of the target application, and look at object values using breakpoints etc. This gives the developer valuable insight into the programming logic, thereby helping in localizing the bug. Unfortunately, these approaches generally have too high an overhead to be used in real production systems. On the other hand, production level monitoring tools such as DTrace \cite{dtrace} and systemtap \cite{systemtap} rarely provide enough information to localize the bug.
 Recently, approaches such as Chaos Monkey\cite{chaosmonkey} from Netflix and AB Testing\cite{abtesting}  use ``testing in the wild'' to check for errors and robustness of the software in the production environment itself. 
 However, these approaches are still restricted to only a few areas such as fault tolerance, and software updates. 



%In general, debugging in the development environment can be (1). Unrealistic because it may not be possible to faithfully reconstruct the production environment, (2). Incomplete, as it may be impossible to generate all possible input cases (3). Costly, as it is unfeasible to test all possible configurations given time and cost constraints of releasing the software to the field. 
%Hence debugging is not only difficult because of difficulty to recreate production scenarios, it is also increasingly important to localize and fix bugs in a very short period of time.

%Some approaches such as Chaos Monkey\cite{chaosmonkey} from Netflix, and AB Testing\cite{abtesting} already use ``testing in the wild'' to check for errors and robustness of the software, or to check for new features that have been added.  
%However, despite a clear need, testing in the wild has never gotten much traction in real-world applications as it consumes too much performance bandwidth and more importantly, it can affect the sanity\footnote{The state of the production server may change leading to a crash or wrong output} of real operational state of the software.

%Another trend embraced by mainstream companies such as Flickr, Twitter, Facebook and Google is DevOps\cite{devops}. 
%And wile testing, analyzing and monitoring are an important aspect of the devops cycle, usually only a very small performance bandwidth in the production server can be dedicated to QA operations as compared to real user activity(so as to not effect user-perceived delay). 

%Embedding test-case logic within the context of the application will result in state-change, or performance slow-down that would otherwise not be there in an optimized implmentation of the application.
%This is something which is usually unacceptable in user-facing applications.
%The authors have previously looked into amortizing the cost of running the test, by running it in parallel \cite{invite}.
%However such approaches cannot completely avoid the slowdown, and additonally do not completely sandbox the effects of the test case on the production server. 

%An alternate approach is to record live applications, and replay them offline.
%Over the years there have been several systems which have explored this direction with promising results.
%However most record and replay systems have high overheads, and require replication of the running configuration which may not be possible. 
%Additionally the administrator needs to wait for offline analysis, instead of doing real-time diagnosis.

%On the other hand, there has been an impressive increase in the scale of computing resources, and distributed scalability of infrastructure.
%Web based applications are often hosted in cloud environments, this allows for easily scaling up the hardware resources.
%This often allows for redundant computation, which can be used for testing purposes. 
\iffalse
What makes debugging easier in the development environment? The main reason is because developers can trace the execution flow of the program using tools such as gdb, valgrind\cite{valgrind} etc. and look at object values for the given input using breakpoints or watchpoints. 
Furthermore the input and the system configuration is available to them.
%This gives them an immediate insight as to whether the application is behaving correctly, and where the bug could be.
Unfortunately, such techniques are not possible in the production environment as they would lead to unacceptable slow-down, alter the application functionality, or worse crash the application.
We envision providing \textbf{``live debugging''} for in-production applications in order to significantly reduce the time towards bug resolution.
Most modern day service oriented applications are hosted on IAAS cloud providers, and can hence be easily scaled  up. 
We propose leveraging this abundance of resources for on the fly debugging.
Using user-space virtualization technology(OpenVZ/LXC\cite{openvz,lxc}), we present a debugging mechanism which allows the user to dynamically insert probes in a \emph{cloned} production environment without effecting the actual application, thereby enabling real-time diagnosis.
\fi

\textbf{The future: } We envision providing \textbf{``live debugging functionality''} for in-production applications in order to significantly reduce the time towards bug resolution.
Most modern day service oriented applications are hosted on IAAS cloud providers, and can hence be easily scaled  up. 
We propose leveraging this abundance of resources for on the fly debugging.
Using user-space virtualization technology(OpenVZ/LXC\cite{openvz,lxc}), we present a debugging mechanism which allows the user to dynamically insert instrumentation in a \emph{cloned} production environment without impacting the actual application, thereby enabling real-time diagnosis.
Our system \parikshan allows capturing the context of an application, by cloning a production server and creating two containers: a production container, and a debug-container. 
\parikshan duplicates the incoming traffic to both the containers using a custom proxy, which ignores the responses from the debug-container. 
The debugging on the debug-container is done on the fly using dynamic instrumentation whenever required. 
%This is achieved by using dynamic instrumentation mechanisms to clone a VM by forking off from a running executed state and encapsulating the forked execution in a VM.
%The user can pre-define probe points for dynamically inserting test-cases (by default the entry and exit of each function is considered a probe point).
Since the debugging is done in a container it acts like a sandbox which restricts it from causing any perturbation to the state of the parent process, or impacting the sanity of the responses to the production client.
We introduce ``live cloning'' a process similar to ``live migration'' \cite{vmperformance} where we clone a running container, to another physical host, and ensuring that both of them continue running without suspending the application services.
%, and follow it up with frequent synchronization for long running tests.

%\textit{Parikshan}
%We provide a flexible framework which allows user access to a parallel test-container which behaves identically as the production container. 
%While we discuss several case-studies to debug/ test production applications that show how our framework can be used, we wish to stress that \textbf{the main advantage of \parikshan is a harness/ framework for testing/ debugging in a live environment rather than a new testing methodology}. 
\textit{\textbf{Contributions:}} This framework is a paradigm shift in application debugging, and allows faster bug resolutions:

\begin{itemize}[leftmargin=*]

 \item The developer can use the \textbf{sandbox environment to  safely and securely debug} the production application.
 This includes adding watchpoints, breakpoints, increasing instrumentation, back-in-time debugging  etc..  
%This allows for a safe and secure mechanism to perturb and diagnose the application, \textbf{without effecting the functionality} of the  production container.

 \item A debugging harness, and proxy that does non-blocking request duplication to the debug-container, which ensures \textbf{no performance impact} on the production container. 

 \item Our tool tracks the \textbf{fidelity of the debug-container} (if the debug-container faithfully represents the production container) and creates a flag whenever the containers are out-of-sync.
%The time till which the debug-container maintains fidelity is called it's \emph{debugging-window}( see section \ref{sec:design}).

%\item We allow for \textbf{dynamic insertion of probes}, and safely capturing the execution trace of the application. 
%Dynamically inserting probes is important to avoid relaunching binaries in the test-container. 
%Restarting binaries would break active network connections, and destroy the in memory state of the test container(note: configuration/file-system state is still preserved).
%In our case studies we show how dynamic instrumentation mechanisms can be used with \parikshan

%\item One of the key advantages of our approach is that it is \textbf{language agnostic}. 
%Since the underlying mechanism takes advantage of containers as a platform to do the cloning, the language or interface does not matter as far as cloning is concerned. 
%Of-course testing mechanisms may differ depending upon different languages.

\end{itemize}

%Frequent synchronization is necessary because the test container can potentially go out of sync with the production because of non-determinism or because a test-case changes the state of the container, and effects future problems. 

%\textit{@Nipun edit -> consider why use user-space containers instead of VMs?}
%While VM virtualization has existed for several years, recent advances in user-space container technologies, along with support for migration, has created a space for light-weight testing in live environments.
%Technically our sandbox techniques could also be applied using more traditional Virtual Machines. 
%However, the overhead of using Virtual Machines is considerably higher, and it would technically require double the amount of resources for the target production servers.
%User-Space containers reduce this overhead considerably by using the resources in the same machine.
%We believe the availablity of resources in IAAS cloud infrastructures combined 


%\texttt{Zero-Probe Effect} probe points are added to the application which can be activated to insert test cases using ptrace\cite{ptrace}.
%The use of dynamic instrumentation capability to add test cases in an application is an extension of our previous work of a dynamic instrumentation tool iProbe \cite{iProbe}

%Traditional testing approaches break states and are unable to  
%The authors previous work in in-vivo testing\cite{invite} explored testing in the wild by initiating test cases in the production environment and sharing the load across several instances of deployed application.
%This approach adds test-cases in predetermined functions before starting the execution of the process, and periodically executes them in the run-time environment based on a probabilistic function. 

%\cite{dapper}
%\input{motivation}
\input{contributions}
