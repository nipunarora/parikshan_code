\section{Introduction}
\label{sec:intro}

\begin{figure*}[ht!]
	\begin{center}
		%    \includegraphics[width=0.7\textwidth]{figs/motivation.eps}
		\includegraphics[width=0.9\textwidth]{figs/workflow3.pdf}
		\caption{Workflow of \parikshan in a live multi-tier production system with several interacting services. When the administrator of the system observes errors in two of it's tiers, he can create a sandboxed clone of these tiers and observe/debug them in a sandbox environment without impacting the production system.}
		\label{fig:motivation}
	\end{center}
\end{figure*}

Rapid resolution of incidence~(error/alert) management~\cite{sasase2013} in online service oriented systems is extremely important.
However, the complexities of virtualized environments coupled with large distributed systems have made bug localization harder. 
%The large scale of such systems means that any downtime has significant financial penalties for all parties involved.
On the other hand, there is a trend in the software engineering industry towards closer coupling between software developers and operators~(DevOps~\cite{devops}) in order to have shorter release and debug cycles 
(Facebook mobile has 2 releases a day, and Flickr has 10 deployment cycles per day~\cite{10DevOps}). 
%This re-emphasizes the need to have a very short time to diagnose and fix a bug.
Hence, debugging is hard not only because of difficulty to capture the root-cause, there is also an increased emphasis on the need to localize and fix bugs in a short period of time.

%Furthermore, whether to repair flaws or add features, software patches are released all the time.
%For instance, Facebook mobile has 2 releases a day, and Flickr has 10 deployment cycles per day~\cite{10DevOps}).
%Hence, it is increasingly important to localize and fix bugs in a very short period of time.
%As application software grows and gets more complicated, debugging large scale applications has become increasingly important. 
%This problem is further compounded by the recent trend in software engineering industry by large companies towards DevOps \cite{devops}. 
%The recent trend towards DevOps~\cite{devops} by the software engineering industry further compounds this problem. 
%by requiring a fast and rapid resolution towards any software bug.
%DevOps stresses on close coupling between software developers and operators, in order to have shorter release cycles (Facebook mobile has 2 releases a day, and Flickr has 10 deployment cycles per day~\cite{10DevOps}). 
%This re-emphasizes the need to have a very short time to diagnose and fix a bug.
%Hence, debugging is hard not only because of difficulty to capture the root-cause, it is also increasingly important to localize and fix bugs in a very short period of time.

Existing state-of-art techniques for monitoring production systems~\cite{dtrace, iProbe, winetw} rely on light-weight dynamic instrumentation to capture execution traces. 
Operators then feed these traces to analytic tools~\cite{magpie,clue} or do offline debugging, to find the root-cause of the error.
However, dynamic instrumentation has a trade-off between granularity of tracing and the performance overhead. 
Operators keep instrumentation granularity low, to avoid higher overheads in the production environment.
This often leads to multiple iterations between the debugger and the operator, to increase instrumentation in specific modules, in order to diagnose the root-cause of the bug. 
%To avoid higher overheads instrumentation granularity is generally kept low, thereby making bug diagnosis harder.
%Debugging is a lengthy process: debuggers try to piece together what could be the possible problem using log information.
%Often more information is required to understand the context better which leads to several iterations before the problem is debugged, thereby increasing the time-to-debug.

Another body of work has looked into record-and-replay~\cite{odr,revirt,laadan2010transparent,geels2007friday} systems which capture execution traces, in order to faithfully replay them in an offline environment.
These systems try to capture system level information, user-input, as well as all possible sources of non-determinism, to allow for in-depth \textit{post-facto} analysis of the error.
%Another tool, aftersight~\cite{aftersight} looks into recording, and replaying the execution in parallel, to allow for decoupled analysis. 
However, owing to the amount of instrumentation required, record-and-replay tools introduce an even heavier overhead. 
This may make them unacceptable for several user-facing systems where performance is essential.


%However, it is extremely difficult to meet the quick debugging demands of a devops environment, as it is not feasible to recreate realistic workloads in an offline development environment for large scale multi-tier or cloud based applications.
%\noindent
%Existing techniques for monitoring production systems~\cite{dtrace, iProbe, winetw} rely on light-weight dynamic instrumentation in either the kernel or the application. 
% kernel, application or error logs.  
%as a mechanism to localize and identify the bugs as well.
%There are several problems with these techniques:
%\begin{itemize}[leftmargin=*,topsep=0pt,itemsep=-1ex,partopsep=1ex,parsep=1ex]
%\textbf{Unrealistic} because 
%\item %These techniques rely on instrumentation to gather execution traces.
%Dynamic instrumentation has a trade-off between granularity of tracing and the performance overhead. 
%Operators usually avoid high instrumentation in live production system.
%Hence, the logs captured may not be enough to find root-cause of the error.
%\item Applications use a variety of third party plugins, are deployed on multiple kernels, which makes generating configurations and state of production systems difficult. 
 % traditional whitebox testing in the development environment is unable to capture these bugs.
%\item Debugging is a lengthy process: Developers try to piece together what could be the possible problem using log information.
%Often more information is required to understand the context better which leads to several iterations before the problem is debugged.
%\end{itemize}

%\noindent
%Recent work in record-and-replay~\cite{} tools allows operators to capture the context of the application and reproduce bugs in an offline environment.
%However, these tools incur a relatively high overhead, and can thereby not be used in production systems. 

%One of the proposed mechanisms of addressing this problem is to ``perpetually test''~\cite{perpetual} the application in the field after it has been deployed. 
%This is important since testing in a production system enables us to capture previously ``unreachable'' system states, which can arise due to various factors such as unpredictable user environment, outdated software, an ever increasing list of hardware devices (e.g. mobile phones, embedded devices etc.), or simply because of imperfect network connectivity (wifi, cellular).
%which are possible only for a long running production environment. 
%Since we are testing in a real environment, we get real user-input for test-cases, and are able to test a real environment.
%However, perpetual testing has never gotten much traction because of an obvious flaw : executing such test-cases will adversely effect the user-experience, both in performance and potentially in application logic.

%\noindent
%Previous approaches such as Chaos Monkey~\cite{chaosmonkey} from Netflix and AB Testing~\cite{abtesting} already use ``testing in the wild'' to check for errors and robustness of the software or to check for new features that have been added.  
%However, despite a clear need, debugging in the production environment has never gotten much traction in real-world applications as it may consume too much performance bandwidth and more importantly, it can impact the sanity\footnote{The state of the production server may change leading to a crash or wrong output} of real operational state of the software.
%Another trend embraced by mainstream companies such as Flickr, Twitter, Facebook and Google is DevOps\cite{devops}. 
%And wile testing, analyzing and monitoring are an important aspect of the devops cycle, usually only a very small performance bandwidth in the production server can be dedicated to QA operations as compared to real user activity(so as to not effect user-perceived delay). 

%Embedding test-case logic within the context of the application will result in state-change, or performance slow-down that would otherwise not be there in an optimized implmentation of the application.
%This is something which is usually unacceptable in user-facing applications.
%The authors have previously looked into amortizing the cost of running the test, by running it in parallel \cite{invite}.
%However such approaches cannot completely avoid the slowdown, and additonally do not completely sandbox the effects of the test case on the production server. 

%An alternate approach is to record live applications, and replay them offline.
%Over the years there have been several systems which have explored this direction with promising results.
%However most record and replay systems have high overheads, and require replication of the running configuration which may not be possible. 
%Additionally the administrator needs to wait for offline analysis, instead of doing real-time diagnosis.

%On the other hand, there has been an impressive increase in the scale of computing resources, and distributed scalability of infrastructure.
%Web based applications are often hosted in cloud environments, this allows for easily scaling up the hardware resources.
%This often allows for redundant computation, which can be used for testing purposes. 

%The main reason that debugging in the development environment is easier, is because developers can trace the execution flow of the program using tools such as gdb~\cite{gdb}, valgrind~\cite{valgrind} etc. and look at variable values for the given input. 
%This gives them an immediate insight as to whether the application is behaving correctly, and where the bug could be.
%Unfortunately, such techniques are not possible in the production environment as they would lead to unacceptable slow-down, alter the application functionality, or worse crash the application.

%The work aims to provide \textbf{``bug diagnosis as a service''} for real-time debugging and analysis of production applications, with no recording overhead on the production application.
%We observe that most modern day service oriented applications are hosted on IAAS cloud providers, and can hence be easily scaled  up. 
%Additionally, there have been rapid advances in user-space virtualization technologies such as Docker~\cite{docker}, and OpenVZ/LXC~\cite{openvz,lxc}, which allow users to easily launch and create light-weight application containers. 
%Check THIS LINE
%In particular, docker provides pre-installed containers(webservers, loadbalancers, appservers) which can be integrated together to create a service.
%Leveraging this abundance of resources, we present a debugging mechanism, which allows the user to dynamically insert probes in a \emph{cloned} production environment without impacting the actual application: thereby, enabling real-time diagnosis.

Our system, called \parikshan\footnote{\parikshan is the Sanskrit word for  testing}, allows \textbf{real-time debugging} without any performance impact on the production service. 
We provide a facility to sandbox the production and debug environments such that any modification in the debug environment does not impact user-facing operations.
%\parikshan can target specific sections of a running large scale distributed application, avoiding the need for a scaled out offline debugging cluster.
In particular, \parikshan allows system administrators to apply debugging techniques with deeper granularity instrumentation, without impacting performance or functionality.
For the remainder of this paper, we define \textbf{downstream servers} as servers from which requests are being sent to the production container, and \textbf{upstream servers} as servers to which the production container sends request. 
In Figure~\ref{fig:workflow}, the webserver is downstream, and the backend is upstream of our target container.

%We avoid recording overhead in the production container, while providing a facility for deeper bug diagnosis, and instrumentation.
%We have deployed \parikshan in  cloud infrastructure using user-space containers.

\parikshan leverages an abundance of resources available in the cloud environments to launch servers (debug containers) for the express purpose of debugging cloned from a running production system (production container). 
It is composed of three modules:
(a) a \textit{clone manager}, which manages cloning of production containers to debug containers.
(b) a \textit{network duplicator} module, which duplicates all incoming traffic from downstream servers to both production and debug containers.
(c) a \textit{network aggregator} module, which manages all communication from upstream servers to the debug-container.
The cloning operation is ``live'', hence there is no suspension of the services of the production server.
The debug container acts like a sandbox which restricts it from causing any perturbation to the state of the parent process, or impacting the sanity of the responses to the production client. 
This allows debuggers to use debugging tools without any fear of crashing or modifying the production application.

\iffalse
This is done by cloning an application container, and creating two containers: a production container, and a debug container. 
We duplicate incoming traffic from downstream servers to both production and debug containers.
Similarly, we have another module, which replays responses sent from the production container, to the debug container so that it is completely isolated from the network. 
The debugging on the debug-container is done on-the-fly using dynamic instrumentation tools like DTrace~\cite{dtrace}, or iProbe~\cite{iProbe}. 
%hence any set of test-cases can be turned on whenever required. 
%This is achieved by using dynamic instrumentation mechanisms to clone a VM by forking off from a running executed state and encapsulating the forked execution in a VM.
%The user can pre-define probe points for dynamically inserting test-cases (by default the entry and exit of each function is considered a probe point).
The cloned debug container acts like a sandbox which restricts it from causing any perturbation to the state of the parent process, or impacting the sanity of the responses to the production client. 
The cloning operation is ``live'', hence there is no suspension of the services of the production server.
\fi

\parikshan primarily focuses on non-crashing bugs~\cite{Zhang:2013:ADS:2486788.2486830, liu2005mining, kremenek2007factor}.
These bugs lead to either an inconsistent output or impact the performance of the application, without crashing the system.
Examples of such bugs are slow memory leaks, configuration errors, and performance bugs, which do not crash the application, but need to be fixed quickly to avoid degradation in service quality. 
Although many interesting methods have been developed to trace crashing bugs (memory violation, core dumps etc.), it is still difficult to analyze non-crashing bugs as they often happen in scaled out systems or because of difficult to reproduce edge-case scenarios.
%that are hard to replicate in unit tests or integration tests. 

We have deployed \parikshan in the context of cloud platform using user-space container virtualization technologies (OpenVZ/LXC~\cite{openvz,lxc}).
%A key insight of our design is that redundant resources often available in cloud infrastructures can be used for debugging purposes, while making the debugging process more efficient and reliable.
We assume that our target systems utilizes micro-service architectures (\texttt{Docker}~\cite{docker}), where each service (application, DNS, indexing, storage) is sandboxed in separate containers.
This allows us to launch debug-containers, which can target one application at a time.
Our techniques can also be applied to traditional VM's. 
However, containers are more light-weight, and utilize far less resources.
%While full VM virtualization has existed for several years, recent advances in user-space container technologies (OpenVZ/LXC~\cite{openvz,lxc}) has changed software engineering methodology. 
%Furthermore, container based technologies like \texttt{Docker}~\cite{docker} emphasize the use of micro-service architectures, where each service (application, DNS, indexing, storage) is sandboxed in separate containers. 


%In particular, there have been rapid advances in user-space virtualization technologies such as Docker~\cite{docker}, and , which allow users to easily launch and create light-weight application containers. 
%\textit{Parikshan}
%We provide a flexible framework which allows user access to a parallel test-container which behaves identically as the production container. 
%While we discuss several case-studies to debug/ test production applications that show how our framework can be used, we wish to stress that \textbf{the main advantage of \parikshan is a harness/ framework for testing/ debugging in a live environment rather than a new testing methodology}. 
\noindent
%\parikshan provides a facility for diagnosing bugs in containers cloned from a production system. 
The key contributions of our system are:
\begin{itemize}[leftmargin=*,topsep=0pt,itemsep=-1ex,partopsep=1ex,parsep=1ex]
\item \textbf{Sandbox debugging:} \parikshan provides a cloned sandbox environment to debug the production application.
This allows a safe mechanism to diagnose the error, without impacting the functionality of the application.
\item \textbf{No performance impact:} A network duplication and aggregation mechanism, which ensures non-blocking request duplication to the debug-container, thereby ensuring no performance impact on the application. 
\item \textbf{Capture large-scale context:} Allows to capture the context of large scale production systems, with long running applications. Under normal circumstances capturing such states is extremely difficult as they need a long running test input, and large test-clusters.
\item \textbf{Short time-to-debug:} These techniques contribute to a shortened debug time, by allowing users to directly gather trace data rather than wait for operators. 
%\item \textbf{Track debug container fidelity:} We track the fidelity of the debug-container (debug-container faithfully represents the production container). 
%and creates a flag whenever the containers are out-of-sync. 
%Parikshan debug-containers can tolerate some degree of divergence from the production state. 
%The debug-container may continue to run correctly even if the analysis run on it perturbs it's state slightly (it can tolerate some divergence from the production).
%The time till which the debug-container can faithfully represent the execution is called it's \emph{debugging -window} (see section \ref{sec:window}).
%\item We allow for \textbf{dynamic insertion of probes}, and safely capturing the execution trace of the application. 
%Dynamically inserting probes is important to avoid relaunching binaries in the test-container. 
%Restarting binaries would break active network connections, and destroy the in memory state of the test container(note: configuration/file-system state is still preserved).
%In our case studies we show how dynamic instrumentation mechanisms can be used with \parikshan

%\item One of the key advantages of our approach is that it is \textbf{language agnostic}. 
%Since the underlying mechanism takes advantage of containers as a platform to do the cloning, the language or interface does not matter as far as cloning is concerned. 
%Of-course testing mechanisms may differ depending upon different languages.
\end{itemize}


%\parikshan has been deployed on cloud IAAS platform using user-space container virtualization technologies (OpenVZ/LXC~\cite{openvz,lxc}).
%We tested \parikshan on several real world system, using realistic workloads.
\noindent
The rest of the paper is organized as follows.
In section~\ref{sec:motivation}, we describe a motivating scenario.
Section~\ref{sec:design} and \ref{sec:implementation} describe the design and implementation.
Next we discuss several real-world bugs(Section~\ref{sec:casestudy}), followed by the evaluation (Section~\ref{sec:evaluation}).
In Section~\ref{sec:application}, we discuss potential applications of \parikshan. 
Finally, we discuss some challenges(Section~\ref{sec:threats}), give some related work(Section~\ref{sec:related}) and conclude (Section~\ref{sec:conclusion}).

%\textbf{Virtual Machines vs Containers:} 
%Frequent synchronization is necessary because the test container can potentially go out of sync with the production because of non-determinism or because a test-case changes the state of the container, and effects future problems. 
%\textit{@Nipun edit -> consider why use user-space containers instead of VMs?}
%While VM virtualization has existed for several years, recent advances in user-space container technologies, along with support for migration, has created a space for light-weight testing in live environments.
%Technically our sandbox techniques could also be applied using more traditional Virtual Machines. 
%However, the overhead of using Virtual Machines is considerably higher, and it would technically require double the amount of resources for the target production servers.
%User-Space containers reduce this overhead considerably by using the resources in the same machine.
%We believe the availablity of resources in IAAS cloud infrastructures combined 
%\texttt{Zero-Probe Effect} probe points are added to the application which can be activated to insert test cases using ptrace~\cite{ptrace}.
%The use of dynamic instrumentation capability to add test cases in an application is an extension of our previous work of a dynamic instrumentation tool iProbe \cite{iProbe}
%Traditional testing approaches break states and are unable to  
%The authors previous work in in-vivo testing~\cite{invite} explored testing in the wild by initiating test cases in the production environment and sharing the load across several instances of deployed application.
%This approach adds test-cases in predetermined functions before starting the execution of the process, and periodically executes them in the run-time environment based on a probabilistic function. 
%\cite{dapper}
\input{motivation}
%\input{contributions}
