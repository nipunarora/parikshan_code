\section{CaseStudies}
\label{sec:casestudy}

Here we show how \parikshan can be applied to some real-life bugs.
Table \ref{table:casestudy} shows several bugs which we debugged using \parikshan, and the various techniques we used to localize the bug.
%Parikshan enables the users to freely run any test-case in the test-container while not effecting the production container. 
%At the same time the output of these tests should not effect the functionality or the performance of the production system.
%The main advantage of such a system can be seen in service oriented applications which are user facing and can hence ill-afford to be shutdown for inspecting bugs.
%As mentioned earlier, another major advantage is that we are able to capture live user-input. \\

\begin{table*}[ht]
\begin{tabular}{|c|c|c|c|c|c|c|c|}
	\hline
	Bug Type                                                                         & Bug Desc                                                                   & Application           & \begin{tabular}[c]{@{}c@{}}Tool \\ Used\end{tabular}       & \begin{tabular}[c]{@{}c@{}}Debug \\ Mechanism\end{tabular}   & Slowdown              & \begin{tabular}[c]{@{}c@{}}Nodes\\ Cloned\end{tabular} & \begin{tabular}[c]{@{}c@{}}Comments/\\ Bug Caught\end{tabular}               \\ \hline
	\multirow{3}{*}{\begin{tabular}[c]{@{}c@{}}Performance \\ Bug\end{tabular}}      & \#15811                                                                    & MySQL                 & iProbe                                                     & \begin{tabular}[c]{@{}c@{}}Execution \\ Trace\end{tabular}   & 1.5x                  & 1                                                      & \begin{tabular}[c]{@{}c@{}}Yes - Potentially\\ faster debugging\end{tabular} \\ \cline{2-8} 
	&                                                                            & Apache                & iProbe                                                     & \begin{tabular}[c]{@{}c@{}}Execution \\ Trace\end{tabular}   &                       & 1                                                      & \begin{tabular}[c]{@{}c@{}}Yes - Potentially\\ faster debugging\end{tabular} \\ \cline{2-8} 
	&                                                                            & MySQL                 & iProbe                                                     & \begin{tabular}[c]{@{}c@{}}Execution \\ Trace\end{tabular}   &                       & 1                                                      & \begin{tabular}[c]{@{}c@{}}Yes-Potentially\\ faster debugging\end{tabular}   \\ \hline
	\multirow{2}{*}{\begin{tabular}[c]{@{}c@{}}Memory \\ Leak\end{tabular}}          & Injected                                                                   & Glassfish             & \begin{tabular}[c]{@{}c@{}}VisualVM\\ /mTrace\end{tabular} & \begin{tabular}[c]{@{}c@{}}Memory\\ Profiling\end{tabular}   & 6x                    & 1                                                      & \begin{tabular}[c]{@{}c@{}}Yes - Timeouts\\ \\ in GlassFish?\end{tabular}    \\ \cline{2-8} 
	&                                                                            & MySQL                 & Valgrind                                                   & \begin{tabular}[c]{@{}c@{}}memcheck\\ /heapdump\end{tabular} & N.A                   & 1                                                      & \begin{tabular}[c]{@{}c@{}}Yes - but MySQL \\ restart needed\end{tabular}    \\ \hline
	\multirow{2}{*}{\begin{tabular}[c]{@{}c@{}}Configuration \\ Errors\end{tabular}} &                                                                            & JBOSS                 &                                                            &                                                              &                       & 3                                                      & \begin{tabular}[c]{@{}c@{}}Yes\\ High Cost\end{tabular}                      \\ \cline{2-8} 
	& \begin{tabular}[c]{@{}c@{}}Max Threshold\\ for no. of threads\end{tabular} & MySQL                 &                                                            &                                                              &                       &                                                        & \begin{tabular}[c]{@{}c@{}}Yes - helps catch\\ bug at scale\end{tabular}     \\ \hline
	\multirow{2}{*}{\begin{tabular}[c]{@{}c@{}}Concurrency \\ Bug\end{tabular}}      & \begin{tabular}[c]{@{}c@{}}Atomicity \\ Violation\end{tabular}             & Apache                &                                                            &                                                              &                       &                                                        & Maybe                                                                        \\ \cline{2-8} 
	& \begin{tabular}[c]{@{}c@{}}Race\\ Condition\end{tabular}                   & Apache                &                                                            &                                                              &                       &                                                        & Maybe                                                                        \\ \hline
	\multirow{2}{*}{Crash Bugs}                                                      & Server Crash                                                               & Apache                & N.A                                                        & N.A                                                          &                       &                                                        & Cannot Debug                                                                 \\ \cline{2-8} 
	& Request Crash                                                              & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{}                                      & \multicolumn{1}{l|}{}                                        & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{}                                  & Yes                                                                          \\ \hline
\end{tabular}

\caption{CaseStudy of various production system bugs}
\label{table:casestudy}
\end{table*}

\subsection{Debug Tools and Mechanisms}
\label{sec:debugMechanisms}

%In this section we briefly mention various debug mechanisms, and what they generally involve. 
%We discuss how they can be successfully applied to bug cases we found in production systems in the next subsection.
The idea behind \parikshan is to allow users to use various debugging tools and mechanisms that one would normally use in the development environment, to aslo be applicable in the production environment.
Debugging tools and mechanisms allow developers to better understand program flow, and data flow in the program, which is key to localizing the root cause of any bug.
Program flow can mostly be understood by dynamic instrumentation which can generate \textbf{execution traces}. 
This can tell the developer which functions were executed, and which conditional statements were met during the execution.
Data flow on the other hand requires much finer instrumentation. 
Tools like gdb allow users to insert \textbf{breakpoints}, or \textbf{watchpoints} on variables, to track data-flow whenever a certain variable is triggered.
The downside to this is that it halts progress in the application, unlike execution trace which imposes a slowdown. 
Other mechanisms such as \textbf{delta-debugging}, and \textbf{heap-dump} allow users to modify variables to check if that resolves problems hence changing it's behavior.
In the next subsection we discuss how these techniques can be applied to real-life bugs with the help of the \parikshan framework.

\subsection{Bug Categories}
\label{sec:bugCategories}

\subsubsection{Performance Bugs}
\label{sec:performanceBugs}

One of the most common problems that manifest in production systems is performance bugs especially in usecases which were earlier not thought of during stress testing, and hence the application was not optimized for such transactions.
Such bugs don't usually lead to crashes, but cause significant impact on user satisfaction.
%The problem can manifest itself because of some configuration parameter, or redundant function calls, non-optimal path, and can require either a bug-fix, or a new feature addition.
In a previous case-study\cite{shanluPerf}, the authors found that a significant percentage of real-world performance bugs can be attributed to uncoordinated functions, skippable functions and inefficient synchronization among threads (long locks etc.).
Most such bugs can be caught by function execution tracing with tracking the time taken in each execution function.
Another key insight provided in the case-study, is that two-thirds of the bugs manifested themselves with special input conditions were met, or execution was done at scale. Hence, it is difficult to capture these bugs with traditional white-box testing mechanisms.

In an empirical evaluation of 3 such bugs, we found that a function trace overhead to cause a 1.5x - 2x slowdown in the targeted session of the application. 
With \parikshan and dynamic instrumentation tools such as iProbe\cite{iProbe} we were able to capture a representative execution trace, with no overhead to the production system.
It was reported by users, that some of the user requests were running significantly slower than others.
To test out \parikshan to catch this bug, we re-created a 2 tier client-server setup with the server(container) running a buggy MySQL server application, and made a random workload with several repetitive instances of queries triggering the bug.
We initiated debugging by creating a live clone of the container running the MySQL server.
Using a trial and error method we profiled high granularity functions in MySQL and gradually looked at finer granularity modules to isolate the performance problem.
This allowed us to successfully isolate the function with the performance problem.


The MySQL queries, were only a few KB's so we were able to queue up several requests in the pipe and there was no divergence in the output produced by both the debug container and the production container. 


\subsubsection{Memory Leaks}
\label{sec:memoryLeaks}

Localizing a memory leak takes us further than simply execution tracing. 
Performance debugging usually requires simply execution traces, whereas memory leak analysis needs tools such as Valgrind\cite{valgrind}, which use shadow memory techniques to trace all actively allocated objects.
While shadow-memory tools are good for development debugging, it cannot be applied to real-production environments as they require the service to be closed to compute which objects remained allocated or to show dangling reference(actively allocated memory may or may not be used in the future) etc.. Additionally these tools are resource hungry and have a high overhead (~4-6X).
In our memory leak case study, we first profiled the application to find transactions that could potentially be the cause of the memory leak. 
We then filter out everything except the suspect transactions, and restart mysqld service with valgrind memcheck tool turned on.
The valgrind tool was able to summarize and point to the root-cause of the bug which we validated from the bug report.
In this case the considerable overhead because of valgrind, and the fact that it serialized the execution (other transactions were not able to follow), led to transactions being dropped in the proxy. However, this did not impact us in finding the root cause.

In another memory leak scenario for Java Glassfish\cite{glassfish} app server, we were able to apply a memory profiler(visualVM), to look at allocation and deallocation patterns.
This has comparatively lesser overhead, and can point to stale objects, or can profile how different classes are using the heap memory.
%In cases where memory leak exhibits because of the application state after a long running execution, memory profiling may be a better choice than shadow memory tools, as they require a service restart.
Using memory profiling in \parikshan will allow users to capture the ``long-running'' context of the application which may be important to capture the bug.

\subsubsection{Configuration Bugs}
\label{sec:configurationBugs}



\subsubsection{Concurrency Bugs}
\label{sec:concurrencyBugs}

Concurrency bugs are caused because of non-deterministic execution in multi-threaded applications.
These bugs are particularly difficult to catch in white-box debugging as 

\subsubsection{Integration Bugs}
\label{sec:integrationBugs}

%\subsection{Debugging Techniques}
%\label{sec:debugTechniques}

\iffalse
%\par \noindent
\subsection{CaseStudy 1: Debugging using Execution Tracing of MySQL bug 18511}  
Performance profiling such as function execution trace, execution time, resource usage etc., is often used to indicate and localize performance bugs in real world systems. 
While performance profiling is simple to implement, it obviously incurs an overhead and will effect user-experience of the target system.
Effectively, this means that despite it's advantages, the amount of profiling that can be done in a production system is extremely limited. 

As our first case study we focused on profiling and capturing a performance bug in a session with several randomly created user transactions to MySQL. 
It was reported by users, that some of the user requests were running significantly slower than others.
To test out \parikshan to catch this bug, we re-created a 2 tier client-server setup with the server(container) running a buggy mysql server application, and made a random workload with several repetitive instances of queries triggering the bug.
We initiated debugging by creating a live clone of the container running the mysql server.
Using a trial and error method we profiled high granularity functions in mysql and gradually looked at finer granularity modules to isolate the performance problem.
This allowed us to successfully isolate the function with the performance problem.

We believe this case study shows a classical performance bug, where \parikshan can be used.
Firstly, it's a performance bug which is non-critical i.e. does not lead to crashes etc.
\parikshan has been designed to look into real live bug diagnosis, rather than looking at bugs after a crash etc.
\footnote{A lot of SOA applications are fault tolerant, and can continue even after the crash by relaunching processes etc. Potentially \parikshan can also be used in such a scenario to trace the crash itself.}
Secondly, we assume that the user-input (which caused the bug), occurs fairly frequently.
In this case, a database query which looks into data containing chinese characters, or japanese characters could be a fairly common occurence.
In our experience we found several such performance bugs which occur in only a small percentage of user transactions.
These bugs are often difficult to catch as they happen only in corner case inputs, and generally do not lead to application crashes.
\parikshan would be useful to debug such performance errors, by giving deep insight in a live running system.
\fi

%\par \noindent
%\subsection {CaseStudy 2: Performance Profiling, using dyninst}
%Demand Driven Testing - https://www.cs.virginia.edu/~soffa/Soffa_Pubs_all/Conferences/Demand-driven.Misurda.2005.pdf 

%@Nipun- I don't think either of the next two make a lot of sense
%\par \noindent \textbf{CaseStudy 3: A/B Testing}
%A/B Testing 
%http://www.polteq.com/wp-content/uploads/2013/02/testingexperience20_12_12_Marc_van_t_Veer.pdf

%\par \noindent \textbf{CaseStudy 4: Fault Tolerance Testing}
%Fault Injection to look at fault tolerance
%Fault Injection in netflix http://techblog.netflix.com/2012/07/chaos-monkey-released-into-wild.html
%Security Honeypots? 
