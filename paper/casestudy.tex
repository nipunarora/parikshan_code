
\begin{table*}[!ht]
\begin{tabular}{|c|c|c|c|c|c|c|c|}
\hline
Bug Type                                                                         & Bug Desc                                                                   & Application           & \begin{tabular}[c]{@{}c@{}}Tool \\ Used\end{tabular}       & \begin{tabular}[c]{@{}c@{}}Debug \\ Mechanism\end{tabular}   & Slowdown              & \begin{tabular}[c]{@{}c@{}}Nodes\\ Cloned\end{tabular} & \begin{tabular}[c]{@{}c@{}}Comments/\\ Bug Caught\end{tabular}               \\ \hline
\multirow{3}{*}{\begin{tabular}[c]{@{}c@{}}Performance \\ Bug\end{tabular}}      & \#15811                                                                    & MySQL                 & iProbe                                                     & \begin{tabular}[c]{@{}c@{}}Execution \\ Trace\end{tabular}   & 1.5x                  & 1                                                      & \begin{tabular}[c]{@{}c@{}}Yes - Potentially\\ faster debugging\end{tabular} \\ \cline{2-8} 
                                                                                 & \#45464                                                                    & Apache                & iProbe                                                     & \begin{tabular}[c]{@{}c@{}}Execution \\ Trace\end{tabular}   & 1.4x                  & 1                                                      & \begin{tabular}[c]{@{}c@{}}Yes - Potentially\\ faster debugging\end{tabular} \\ \cline{2-8} 
                                                                                 & \#49491                                                                    & MySQL                 & iProbe                                                     & \begin{tabular}[c]{@{}c@{}}Execution \\ Trace\end{tabular}   & 1.8x                  & 1                                                      & \begin{tabular}[c]{@{}c@{}}Yes - Potentially\\ faster debugging\end{tabular}   \\ \hline
\multirow{2}{*}{\begin{tabular}[c]{@{}c@{}}Memory \\ Leak\end{tabular}}          & Injected                                                                   & Glassfish             & \begin{tabular}[c]{@{}c@{}}VisualVM\\ /mTrace\end{tabular} & \begin{tabular}[c]{@{}c@{}}Memory\\ Profiling\end{tabular}   & 6x                    & 1                                                      & \begin{tabular}[c]{@{}c@{}}Yes - Timeouts\\ in GlassFish\end{tabular}    \\ \cline{2-8} 
                                                                                 & Injected                                                                   & MySQL                 & Valgrind                                                   & \begin{tabular}[c]{@{}c@{}}memcheck\end{tabular} & N.A                   & 1                                                      & \begin{tabular}[c]{@{}c@{}}Yes \\ \end{tabular}    \\ \hline
\multirow{2}{*}{\begin{tabular}[c]{@{}c@{}}Configuration \\ Errors\end{tabular}} & DNS                                                                        & JBOSS                 & Tracing                                                    & DTrace                                                       & 1.5x                   & 2                                                      & Yes                                                                          \\ \cline{2-8} 
                                                                                 & \begin{tabular}[c]{@{}c@{}}Max no.\\ of threads\end{tabular} & MySQL                 & Tracing                                                    & DTrace                                                       & 1.5x                   & 2                                                      & \begin{tabular}[c]{@{}c@{}}Yes\\ \end{tabular}     \\ \hline
%\multirow{2}{*}{\begin{tabular}[c]{@{}c@{}}Concurrency \\ Bug\end{tabular}}      & \begin{tabular}[c]{@{}c@{}}Atomicity \\ Violation\end{tabular}             & Apache                &                                                            &                                                              &                       &                                                        & Maybe                                                                        \\ \cline{2-8} 
%                                                                                 & \begin{tabular}[c]{@{}c@{}}Race\\ Condition\end{tabular}                   & Apache                &                                                            &                                                              &                       &                                                        & Maybe                                                                        \\ \hline
%\multirow{2}{*}{Crash Bugs}                                                      & Server Crash                                                               & Apache                & N.A                                                        & N.A                                                          &                       &                                                        & Cannot Debug                                                                 \\ \cline{2-8} 
%                                                                                 & Request Crash                                                              & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{}                                      & \multicolumn{1}{l|}{}                                        & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{}                                  & Yes                                                                          \\ \hline
\end{tabular}
\caption{CaseStudy of various production system bugs}
\label{table:casestudy}
\end{table*}


\section{CaseStudies}
\label{sec:casestudy}

%Here we show how \parikshan can be applied to some real-life bugs.
%Table \ref{table:casestudy} shows several bugs which we debugged using \parikshan, and the various techniques we used to localize the bug.
%Parikshan enables the users to freely run any test-case in the test-container while not effecting the production container. 
%At the same time the output of these tests should not effect the functionality or the performance of the production system.
%The main advantage of such a system can be seen in service oriented applications which are user facing and can hence ill-afford to be shutdown for inspecting bugs.
%As mentioned earlier, another major advantage is that we are able to capture live user-input. \\

%\subsection{Debug Tools and Mechanisms}
%\label{sec:debugMechanisms}

Many applications have active application transaction logs, and error logs that alert the operator of any anomalous behavior.
Often the information in such logs is insufficient to find the root-cause, and can give false-positives or skip errors altogether.
Using these logs, and their intuition, debuggers run offline test-cases to find the root-cause of the bug. 
This process may need multiple iterations between the operator and developer, as more information may be required: Thereby, increasing the time-to-debug. 
%Since only minimal dynamic instrumentation is allowed, developers go through a trial and error process of increasing the coverage of instrumentation 
%(or have higher instrumentation with the production service suffering an overhead).

%In this section we briefly mention various debug mechanisms, and what they generally involve. 
%We discuss how they can be successfully applied to bug cases we found in production systems in the next subsection.
The idea behind \parikshan is to allow users to use various debugging tools and mechanisms in the production environment, that one would normally use in the development environment.
Debugging tools allow developers to better understand program flow, and data flow in the program, which is key to localizing the root cause of any bug.
Dynamic instrumentation tools can generate \textbf{execution traces}, which give insight into the program flow(functions, conditional statements executed).
%Data flow on the other hand requires much finer instrumentation. 
Tools like dyninst~\cite{dyninst} allow users to insert \textbf{breakpoints}, or \textbf{watchpoints} on variables, to track data-flow whenever a certain variable is triggered.
%The downside to this is that it halts progress in the application, unlike execution trace which imposes a slowdown. 
Other mechanisms such as \textbf{delta-debugging}, and \textbf{heap-dump} allow users to modify variables to check if that resolves problems hence changing it's behavior.
Next, we discuss how these techniques can be applied to real-life bugs with the help of the \parikshan framework.

\subsection{Bug Categories}
\label{sec:bugCategories}

%\subsubsection{Performance Bugs}
%\label{sec:performanceBugs}
\noindent
\textbf{Performance Bugs}: One of the most subtle problems that manifest in production systems is performance bugs.
% especially in usecases which were earlier not thought of during stress testing.
These bugs don't usually lead to crashes, but cause significant impact to user satisfaction.
%The problem can manifest itself because of some configuration parameter, or redundant function calls, non-optimal path, and can require either a bug-fix, or a new feature addition.
In a previous case-study\cite{shanluPerf}, the authors found that a large percentage of real-world performance bugs can be attributed to uncoordinated functions, functions that can skipped and inefficient synchronization among threads (for example locks held for too long etc.).
Typically, such bugs can be caught by function level execution tracing and tracking the time taken in each execution function.
Another key insight provided in the case-study, is that two-thirds of the bugs manifested themselves with special input conditions were met, or execution was done at scale. 
Hence, it is difficult to capture these bugs with traditional white-box testing mechanisms.

\noindent
In an empirical evaluation of 3 such bugs, we found that a function trace overhead to cause a 1.5x - 2x slowdown in the targeted session of the application. 
With \parikshan and dynamic instrumentation tools such as iProbe\cite{iProbe} we were able to capture a representative execution trace, with no overhead to the production system.
For MySQL Bug 15811, it was reported by users, that some of the user requests were running significantly slower than others.
To test out \parikshan to catch this bug, we re-created a 2 tier client-server setup with the server(container) running a buggy MySQL server application, and made a random workload with several repetitive instances of queries triggering the bug.
We initiated debugging by creating a live clone of the container running the MySQL server.
For all transactions with insert queries with a complex character set, we triggered instrumentation to track execution in high granularity functions in insert and character\/string module.
Using the profile for regular latin charactersets, and comparing it to complex charactersets (chinese, japenese) we were easily able to localize the bug to the compare functions in the string module.
%Using a trial and error method we profiled high granularity functions in MySQL and gradually looked at finer granularity modules to isolate the performance problem.
%This allowed us to successfully isolate the function with the performance problem.
%The MySQL queries, were only a few KB's so we were able to queue up several requests in the pipe and there was no divergence in the output produced by both the debug container and the production container. 


%\subsubsection{Memory Leaks}
%\label{sec:memoryLeaks}
\noindent
\textbf{Memory Leaks}: %Localizing a memory leak takes us further than simply execution tracing. 
Memory leak analysis can be done by doing memory allocation function profiling (malloc, free etc.) or using tools like Valgrind\cite{valgrind}, which use shadow memory techniques to trace all actively allocated objects.
While shadow-memory tools are good for development debugging, it cannot be applied to real-production environments as they require the service to be closed to compute which objects remained allocated or to show dangling reference(actively allocated memory may or may not be used in the future) etc.. Additionally these tools are resource hungry and have a high overhead (~4-6X).
In our memory leak case study, we first profiled the application to find transactions that could potentially be the cause of the memory leak. 
We then filter out everything except the suspect transactions, and restart mysqld service with valgrind memcheck tool turned on.
The valgrind tool was able to summarize and point to the root-cause of the bug which we validated from the bug report.
In this case the considerable overhead because of valgrind, and the fact that it serialized the execution (other transactions were not able to follow), led to transactions being dropped in the proxy. 
However, this did not impact us in finding the root cause.

\noindent
In another memory leak scenario for Java Glassfish\cite{glassfish} app server, we were able to apply a memory profiler(visualVM), to look at allocation and deallocation patterns.
This has comparatively lesser overhead, and can point to stale objects, or can profile how different classes are using the heap memory.
%In cases where memory leak exhibits because of the application state after a long running execution, memory profiling may be a better choice than shadow memory tools, as they require a service restart.
Using memory profiling in \parikshan will allow users to capture the ``long-running'' context of the application which may be important to capture the bug.

\noindent
\textbf{Configuration Errors}:
Configuration errors are usually caused by wrong values put in application services by the operators.
This is not necessarily a bug in the program, but a bug in the input.
It is especially difficult to catch, as configuration bugs usually get triggered at scale, or for certain edge cases inputs.
For example in a 3 Tier Application(WebServer, JBoss, MySQL), it was reported that certain queries were returning empty or ``null'' pages. 
The operator can potentially find out which machines in the cluster were affected by this bug.
Since debug logs have not been turned on we can only see the path the query is taking but do not see any error report generated.
This can be used by the operator, to find which containers need to be cloned. 
Using parikshan, it was possible for the developer to clone both the app and the sql server containers to capture the entire flow of some of the queries ( remember the cluster has several machines).
We instrument and follow the execution flow across distributed machines, and were able to see that the mysql server was not creating worker threads for the incoming requests.
Error logs had been turned off for optimization, hence the error could not be easily reported. 
Parikshan, was able to successfully localize the error to misconfiguration in the ``maximum no. of worker thread'' allowed parameter.

%\subsubsection{Configuration Bugs}
%\label{sec:configurationBugs}

%\subsubsection{Concurrency Bugs}
%\label{sec:concurrencyBugs}

%\textbf{Concurrency Bugs}: Concurrency bugs are caused because of non-deterministic execution in multi-threaded applications.
%These bugs are particularly difficult to catch in white-box debugging as 

%\subsubsection{Integration Bugs}
%\label{sec:integrationBugs}
%\subsection{Debugging Techniques}
%\label{sec:debugTechniques}
%\par \noindent
%\subsection {CaseStudy 2: Performance Profiling, using dyninst}
%Demand Driven Testing - https://www.cs.virginia.edu/~soffa/Soffa_Pubs_all/Conferences/Demand-driven.Misurda.2005.pdf
%@Nipun- I don't think either of the next two make a lot of sense
%\par \noindent \textbf{CaseStudy 3: A/B Testing}
%A/B Testing 
%http://www.polteq.com/wp-content/uploads/2013/02/testingexperience20_12_12_Marc_van_t_Veer.pdf
%\par \noindent \textbf{CaseStudy 4: Fault Tolerance Testing}
%Fault Injection to look at fault tolerance
%Fault Injection in netflix http://techblog.netflix.com/2012/07/chaos-monkey-released-into-wild.html
%Security Honeypots? 
\iffalse
%\par \noindent
\subsection{CaseStudy 1: Debugging using Execution Tracing of MySQL bug 18511}  
Performance profiling such as function execution trace, execution time, resource usage etc., is often used to indicate and localize performance bugs in real world systems. 
While performance profiling is simple to implement, it obviously incurs an overhead and will effect user-experience of the target system.
Effectively, this means that despite it's advantages, the amount of profiling that can be done in a production system is extremely limited. 

As our first case study we focused on profiling and capturing a performance bug in a session with several randomly created user transactions to MySQL. 
It was reported by users, that some of the user requests were running significantly slower than others.
To test out \parikshan to catch this bug, we re-created a 2 tier client-server setup with the server(container) running a buggy mysql server application, and made a random workload with several repetitive instances of queries triggering the bug.
We initiated debugging by creating a live clone of the container running the mysql server.
Using a trial and error method we profiled high granularity functions in mysql and gradually looked at finer granularity modules to isolate the performance problem.
This allowed us to successfully isolate the function with the performance problem.

We believe this case study shows a classical performance bug, where \parikshan can be used.
Firstly, it's a performance bug which is non-critical i.e. does not lead to crashes etc.
\parikshan has been designed to look into real live bug diagnosis, rather than looking at bugs after a crash etc.
\footnote{A lot of SOA applications are fault tolerant, and can continue even after the crash by relaunching processes etc. Potentially \parikshan can also be used in such a scenario to trace the crash itself.}
Secondly, we assume that the user-input (which caused the bug), occurs fairly frequently.
In this case, a database query which looks into data containing chinese characters, or japanese characters could be a fairly common occurence.
In our experience we found several such performance bugs which occur in only a small percentage of user transactions.
These bugs are often difficult to catch as they happen only in corner case inputs, and generally do not lead to application crashes.
\parikshan would be useful to debug such performance errors, by giving deep insight in a live running system.
\fi